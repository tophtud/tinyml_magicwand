{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ ì œìŠ¤ì²˜ ì¸ì‹ TinyML í•™ìŠµ íŒŒì´í”„ë¼ì¸ (ê°œì„ ëœ INT8 ì–‘ìží™”)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ë“œëŸ¼ ížˆíŠ¸(Drum_hit), í”¼ì•„ë…¸(piano), ë°”ì´ì˜¬ë¦°(violin) ì œìŠ¤ì²˜ë¥¼ ì¸ì‹í•˜ê¸° ìœ„í•œ TinyML ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. ë°ì´í„° ë¶„ì„ ë° íƒìƒ‰\n",
    "2. ë°ì´í„° ì •ì œ ë° ì „ì²˜ë¦¬\n",
    "3. ë°ì´í„° ì¦ê°• ë° ì‹œê°í™”\n",
    "4. ëª¨ë¸ ì„¤ê³„ ë° í•™ìŠµ\n",
    "5. ëª¨ë¸ í‰ê°€ ë° TFLite ë³€í™˜\n",
    "6. **ðŸš€ ê°œì„ ëœ INT8 ì–‘ìží™” ë° ì„±ëŠ¥ ì ê²€** â­ ëŒ€í­ ê°œì„ \n",
    "7. Arduino ë°°í¬ ê°€ì´ë“œ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë°ì´í„° ë¶„ì„ ë° íƒìƒ‰\n",
    "\n",
    "ë¨¼ì € í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¡œë“œí•˜ê³  ì œìŠ¤ì²˜ ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ ì–‘ìží™” ì¸ì‹ í›ˆë ¨(QAT) ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ - ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì§„í–‰\n",
      "TensorFlow ë²„ì „: 2.5.0\n",
      "ë°ì´í„° ë£¨íŠ¸ ê²½ë¡œ: ./IMU\n"
     ]
    }
   ],
   "source": [
    "# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import time\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ì–‘ìží™” ì¸ì‹ í›ˆë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„ íƒì‚¬í•­)\n",
    "try:\n",
    "    import tensorflow_model_optimization as tfmot\n",
    "    QAT_AVAILABLE = True\n",
    "    print(\"âœ… ì–‘ìží™” ì¸ì‹ í›ˆë ¨(QAT) ì‚¬ìš© ê°€ëŠ¥\")\n",
    "except ImportError:\n",
    "    QAT_AVAILABLE = False\n",
    "    print(\"âš ï¸ ì–‘ìží™” ì¸ì‹ í›ˆë ¨(QAT) ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ - ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì§„í–‰\")\n",
    "\n",
    "# ì‹œë“œ ê³ ì • (ìž¬í˜„ì„± í™•ë³´)\n",
    "SEED = 1337\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "print(f\"TensorFlow ë²„ì „: {tf.__version__}\")\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ ì„¤ì • - ì‚¬ìš©ìž ì§€ì • ê²½ë¡œ\n",
    "DATA_ROOT = \"./IMU\"  # ì‚¬ìš©ìž ì§€ì • ê²½ë¡œ\n",
    "print(f\"ë°ì´í„° ë£¨íŠ¸ ê²½ë¡œ: {DATA_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ë‚ ë‹¤ ì œìŠ¤ì²˜ ë°ì´í„° í´ë”: ./IMU\\up\n",
      "CSV íŒŒì¼ ìˆ˜: 53\n",
      "íŒŒì¼ ì˜ˆì‹œ: gesture_001.csv\n",
      "\n",
      "ì•‰ë‹¤ ì œìŠ¤ì²˜ ë°ì´í„° í´ë”: ./IMU\\down\n",
      "CSV íŒŒì¼ ìˆ˜: 50\n",
      "íŒŒì¼ ì˜ˆì‹œ: gesture_001.csv\n",
      "\n",
      "ëŒë‹¤ ì œìŠ¤ì²˜ ë°ì´í„° í´ë”: ./IMU\\turn\n",
      "CSV íŒŒì¼ ìˆ˜: 51\n",
      "íŒŒì¼ ì˜ˆì‹œ: gesture_001.csv\n"
     ]
    }
   ],
   "source": [
    "# ì œìŠ¤ì²˜ í´ë” ì •ì˜\n",
    "gesture_folders = {\n",
    "    'ë‚ ë‹¤': os.path.join(DATA_ROOT, \"up\"),\n",
    "    'ì•‰ë‹¤': os.path.join(DATA_ROOT, \"down\"),\n",
    "    'ëŒë‹¤': os.path.join(DATA_ROOT, \"turn\")\n",
    "}\n",
    "\n",
    "# ê° í´ë”ì˜ CSV íŒŒì¼ ëª©ë¡ í™•ì¸\n",
    "for gesture_name, folder_path in gesture_folders.items():\n",
    "    csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    print(f\"\\n{gesture_name} ì œìŠ¤ì²˜ ë°ì´í„° í´ë”: {folder_path}\")\n",
    "    print(f\"CSV íŒŒì¼ ìˆ˜: {len(csv_files)}\")\n",
    "    print(f\"íŒŒì¼ ì˜ˆì‹œ: {os.path.basename(csv_files[0]) if csv_files else 'ì—†ìŒ'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ë‚ ë‹¤ ì œìŠ¤ì²˜ ë°ì´í„° ìƒ˜í”Œ (íŒŒì¼: gesture_001.csv)\n",
      "ë°ì´í„° í˜•íƒœ: (120, 6)\n",
      "ì»¬ëŸ¼ëª…: ['aX', 'aY', 'aZ', 'gX', 'gY', 'gZ']\n",
      "ìƒ˜í”Œ ë°ì´í„°:\n",
      "       aX     aY     aZ      gX      gY      gZ\n",
      "0  -0.344 -0.114  0.935  -3.906 -73.059 -21.362\n",
      "1  -0.351 -0.130  0.945   5.310 -72.754 -16.846\n",
      "2  -0.355 -0.163  0.911  13.672 -71.350 -12.451\n",
      "\n",
      "ë‚ ë‹¤ ê¸°ë³¸ í†µê³„:\n",
      "            aY       aZ       gX       gY       gZ\n",
      "count  119.000  119.000  119.000  119.000  119.000\n",
      "mean     0.294    0.025   15.962   96.656   16.623\n",
      "std      0.380    1.424   45.732  192.079   74.554\n",
      "min     -0.522   -2.060  -85.144 -284.363 -146.057\n",
      "25%      0.048   -1.046  -17.486  -55.939  -20.691\n",
      "50%      0.295   -0.302   13.855   87.891   22.461\n",
      "75%      0.543    0.923   51.972  289.032   77.148\n",
      "max      1.038    3.651  127.258  363.342  119.202\n",
      "\n",
      "ì•‰ë‹¤ ì œìŠ¤ì²˜ ë°ì´í„° ìƒ˜í”Œ (íŒŒì¼: gesture_001.csv)\n",
      "ë°ì´í„° í˜•íƒœ: (120, 6)\n",
      "ì»¬ëŸ¼ëª…: ['aX', 'aY', 'aZ', 'gX', 'gY', 'gZ']\n",
      "ìƒ˜í”Œ ë°ì´í„°:\n",
      "      aX     aY     aZ     gX      gY     gZ\n",
      "0  0.732  0.186  0.594  3.601  14.709 -4.150\n",
      "1  0.730  0.181  0.554  5.005  15.076 -5.432\n",
      "2  0.732  0.161  0.511  5.554  15.137 -7.080\n",
      "\n",
      "ì•‰ë‹¤ ê¸°ë³¸ í†µê³„:\n",
      "            aY       aZ       gX       gY       gZ\n",
      "count  119.000  119.000  119.000  119.000  119.000\n",
      "mean     0.048    0.805    5.621  -62.011    6.452\n",
      "std      0.153    0.428   31.185   58.640   15.615\n",
      "min     -0.405   -0.844  -39.551 -149.658  -12.268\n",
      "25%     -0.020    0.448  -14.038 -117.462   -4.792\n",
      "50%      0.024    0.878    0.793  -59.692   -0.488\n",
      "75%      0.134    1.055   16.480    3.662   14.771\n",
      "max      0.609    2.673  211.914  110.474   58.716\n",
      "\n",
      "ëŒë‹¤ ì œìŠ¤ì²˜ ë°ì´í„° ìƒ˜í”Œ (íŒŒì¼: gesture_001.csv)\n",
      "ë°ì´í„° í˜•íƒœ: (120, 6)\n",
      "ì»¬ëŸ¼ëª…: ['aX', 'aY', 'aZ', 'gX', 'gY', 'gZ']\n",
      "ìƒ˜í”Œ ë°ì´í„°:\n",
      "       aX     aY     aZ     gX      gY      gZ\n",
      "0  -1.165  0.131  0.517 -3.662   7.202  39.612\n",
      "1  -1.145  0.132  0.619  0.244  14.587  40.710\n",
      "2  -1.127  0.090  0.601  1.953  26.123  40.710\n",
      "\n",
      "ëŒë‹¤ ê¸°ë³¸ í†µê³„:\n",
      "            aY       aZ       gX       gY       gZ\n",
      "count  119.000  119.000  119.000  119.000  119.000\n",
      "mean     0.002   -0.372   41.046    0.168   34.565\n",
      "std      1.122    1.425   78.504  260.686  175.894\n",
      "min     -2.485   -2.813 -101.318 -428.955 -251.221\n",
      "25%     -0.644   -1.491  -21.484 -212.830 -130.402\n",
      "50%      0.132   -0.671   33.264  -14.465   46.814\n",
      "75%      0.791    0.730  110.870  212.158  159.790\n",
      "max      2.123    2.209  179.260  496.216  315.308\n"
     ]
    }
   ],
   "source": [
    "# ê° ì œìŠ¤ì²˜ í´ë”ì—ì„œ ì²« ë²ˆì§¸ CSV íŒŒì¼ì„ ìƒ˜í”Œë¡œ ë¶„ì„\n",
    "for gesture_name, folder_path in gesture_folders.items():\n",
    "    csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    if csv_files:\n",
    "        sample_file = csv_files[0]\n",
    "        df = pd.read_csv(sample_file, skiprows=1)\n",
    "        print(f\"\\n{gesture_name} ì œìŠ¤ì²˜ ë°ì´í„° ìƒ˜í”Œ (íŒŒì¼: {os.path.basename(sample_file)})\")\n",
    "        print(f\"ë°ì´í„° í˜•íƒœ: {df.shape}\")\n",
    "        print(\"ì»¬ëŸ¼ëª…:\", df.columns.tolist())\n",
    "        print(\"ìƒ˜í”Œ ë°ì´í„°:\")\n",
    "        print(df.head(3))\n",
    "        \n",
    "        # ê¸°ë³¸ í†µê³„ ì •ë³´\n",
    "        print(f\"\\n{gesture_name} ê¸°ë³¸ í†µê³„:\")\n",
    "        print(df.describe().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„° ì •ì œ ë° ì „ì²˜ë¦¬\n",
    "\n",
    "ë°ì´í„° ì •ì œ ë° ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œëŠ” ë‹¤ìŒ ìž‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:\n",
    "1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "2. ì´ìƒì¹˜ ì œê±°\n",
    "3. ë°ì´í„° ì •ê·œí™”\n",
    "4. ë ˆì´ë¸” ì¸ì½”ë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_path, label, skip_rows=1):\n",
    "    \"\"\"\n",
    "    CSV íŒŒì¼ì—ì„œ ì œìŠ¤ì²˜ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): CSV íŒŒì¼ ê²½ë¡œ\n",
    "        label (int): ì œìŠ¤ì²˜ ë ˆì´ë¸” (0: ë‚ ë‹¤, 1: ì•‰ë‹¤, 2: ëŒë‹¤)\n",
    "        skip_rows (int): ê±´ë„ˆë›¸ í—¤ë” í–‰ ìˆ˜\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (ì „ì²˜ë¦¬ëœ ë°ì´í„°, ë ˆì´ë¸”)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ë°ì´í„° ë¡œë“œ\n",
    "        df = pd.read_csv(file_path, skiprows=skip_rows)\n",
    "        \n",
    "        # ì»¬ëŸ¼ëª… ê³µë°± ì œê±°\n",
    "        df.columns = df.columns.str.strip()\n",
    "        \n",
    "        # ìˆ«ìžë¡œ ë³€í™˜ ë¶ˆê°€ëŠ¥í•œ í–‰ ì œê±°\n",
    "        df = df[pd.to_numeric(df['aX'], errors='coerce').notna()]\n",
    "        df = df.astype(float)\n",
    "        \n",
    "        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ì•žë’¤ ê°’ì˜ í‰ê· ìœ¼ë¡œ ëŒ€ì²´)\n",
    "        df = df.interpolate(method='linear', limit_direction='both')\n",
    "        \n",
    "        # ì´ìƒì¹˜ ì²˜ë¦¬ (3ì‹œê·¸ë§ˆ ê·œì¹™ ì ìš©)\n",
    "        for col in df.columns:\n",
    "            mean = df[col].mean()\n",
    "            std = df[col].std()\n",
    "            df[col] = df[col].clip(mean - 3*std, mean + 3*std)\n",
    "        \n",
    "        # ì›-í•« ì¸ì½”ë”©ëœ ë ˆì´ë¸” ìƒì„±\n",
    "        one_hot_label = np.zeros(3)\n",
    "        one_hot_label[label] = 1\n",
    "        \n",
    "        return df, one_hot_label\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ì˜¤ë¥˜ ë°œìƒ (íŒŒì¼: {file_path}): {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df):\n",
    "    \"\"\"\n",
    "    ê°€ì†ë„ê³„ì™€ ìžì´ë¡œìŠ¤ì½”í”„ ë°ì´í„°ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): ì›ë³¸ ë°ì´í„°í”„ë ˆìž„\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: ì •ê·œí™”ëœ ë°ì´í„°í”„ë ˆìž„\n",
    "    \"\"\"\n",
    "    normalized_df = df.copy()\n",
    "    \n",
    "    # ê°€ì†ë„ê³„ ë°ì´í„° ì •ê·œí™” (ë²”ìœ„: -4 ~ 4)\n",
    "    for col in ['aX', 'aY', 'aZ']:\n",
    "        normalized_df[col] = (df[col] + 4) / 8\n",
    "    \n",
    "    # ìžì´ë¡œìŠ¤ì½”í”„ ë°ì´í„° ì •ê·œí™” (ë²”ìœ„: -2000 ~ 2000)\n",
    "    for col in ['gX', 'gY', 'gZ']:\n",
    "        normalized_df[col] = (df[col] + 2000) / 4000\n",
    "    \n",
    "    return normalized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ë°ì´í„° ì¦ê°• ë° ì‹œê°í™”\n",
    "\n",
    "ë°ì´í„° ì¦ê°•ì„ í†µí•´ í•™ìŠµ ë°ì´í„°ì˜ ì–‘ì„ ëŠ˜ë¦¬ê³  ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì€ ì¦ê°• ê¸°ë²•ì„ ì ìš©í•©ë‹ˆë‹¤:\n",
    "1. ë…¸ì´ì¦ˆ ì¶”ê°€\n",
    "2. ì‹œê°„ ì´ë™\n",
    "3. ìŠ¤ì¼€ì¼ ë³€í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(df, noise_factor=0.05, time_shift_max=5):\n",
    "    \"\"\"\n",
    "    ë°ì´í„° ì¦ê°•ì„ í†µí•´ ì¶”ê°€ ìƒ˜í”Œì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): ì›ë³¸ ë°ì´í„°í”„ë ˆìž„\n",
    "        noise_factor (float): ë…¸ì´ì¦ˆ ê°•ë„\n",
    "        time_shift_max (int): ìµœëŒ€ ì‹œê°„ ì´ë™ ë²”ìœ„\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: ì¦ê°•ëœ ë°ì´í„°í”„ë ˆìž„\n",
    "    \"\"\"\n",
    "    augmented_dfs = []\n",
    "    \n",
    "    # ì›ë³¸ ë°ì´í„° ì¶”ê°€\n",
    "    augmented_dfs.append(df.copy())\n",
    "    \n",
    "    # ë…¸ì´ì¦ˆ ì¶”ê°€\n",
    "    noise_df = df.copy()\n",
    "    for col in df.columns:\n",
    "        noise = np.random.normal(0, noise_factor, size=len(df))\n",
    "        noise_df[col] = noise_df[col] + noise\n",
    "    augmented_dfs.append(noise_df)\n",
    "    \n",
    "    # ì‹œê°„ ì´ë™\n",
    "    time_shift = np.random.randint(1, time_shift_max + 1)\n",
    "    time_shift_df = df.copy()\n",
    "    time_shift_df = pd.concat([time_shift_df.iloc[time_shift:], time_shift_df.iloc[:time_shift]])\n",
    "    time_shift_df.reset_index(drop=True, inplace=True)\n",
    "    augmented_dfs.append(time_shift_df)\n",
    "    \n",
    "    # ìŠ¤ì¼€ì¼ ë³€í™”\n",
    "    scale_factor = np.random.uniform(0.9, 1.1)\n",
    "    scale_df = df.copy()\n",
    "    for col in df.columns:\n",
    "        scale_df[col] = scale_df[col] * scale_factor\n",
    "    augmented_dfs.append(scale_df)\n",
    "    \n",
    "    # ëª¨ë“  ì¦ê°• ë°ì´í„° ê²°í•©\n",
    "    result_df = pd.concat(augmented_dfs, axis=0)\n",
    "    result_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ë°ì´í„° í†µí•© ë° ëª¨ë¸ í•™ìŠµ ì¤€ë¹„\n",
    "\n",
    "ëª¨ë“  ì œìŠ¤ì²˜ ë°ì´í„°ë¥¼ í†µí•©í•˜ê³  ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ë‚ ë‹¤ ì œìŠ¤ì²˜ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "ë°œê²¬ëœ CSV íŒŒì¼ ìˆ˜: 53\n",
      "\n",
      "ì•‰ë‹¤ ì œìŠ¤ì²˜ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "ë°œê²¬ëœ CSV íŒŒì¼ ìˆ˜: 50\n",
      "\n",
      "ëŒë‹¤ ì œìŠ¤ì²˜ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "ë°œê²¬ëœ CSV íŒŒì¼ ìˆ˜: 51\n",
      "\n",
      "ì²˜ë¦¬ëœ ë°ì´í„° í˜•íƒœ: (154, 119, 6), (154, 3)\n"
     ]
    }
   ],
   "source": [
    "def process_all_data():\n",
    "    \"\"\"\n",
    "    ëª¨ë“  ì œìŠ¤ì²˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ì €ìž¥í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (ìž…ë ¥ ë°ì´í„°, ì¶œë ¥ ë ˆì´ë¸”)\n",
    "    \"\"\"\n",
    "    # ë°ì´í„° í´ë” ì •ì˜\n",
    "    data_folders = [\n",
    "        (gesture_folders['ë‚ ë‹¤'], 0, 'ë‚ ë‹¤'),\n",
    "        (gesture_folders['ì•‰ë‹¤'], 1, 'ì•‰ë‹¤'),\n",
    "        (gesture_folders['ëŒë‹¤'], 2, 'ëŒë‹¤')\n",
    "    ]\n",
    "    \n",
    "    # ê²°ê³¼ ì €ìž¥ ë””ë ‰í† ë¦¬ ìƒì„± (ì‚¬ìš©ìž ì§€ì • ê²½ë¡œ)\n",
    "    output_dir = os.path.join(DATA_ROOT, 'processed_data')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for folder_path, label, gesture_name in data_folders:\n",
    "        print(f\"\\n{gesture_name} ì œìŠ¤ì²˜ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\")\n",
    "        csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "        print(f\"ë°œê²¬ëœ CSV íŒŒì¼ ìˆ˜: {len(csv_files)}\")\n",
    "        \n",
    "        for file_path in csv_files:\n",
    "            df, one_hot_label = load_and_preprocess_data(file_path, label)\n",
    "            \n",
    "            if df is not None:\n",
    "                # ë°ì´í„° ì •ê·œí™”\n",
    "                normalized_df = normalize_data(df)\n",
    "                \n",
    "                # ë°ì´í„° ê¸¸ì´ ë§žì¶”ê¸° (119ê°œ í–‰ìœ¼ë¡œ ê³ ì •)\n",
    "                if len(normalized_df) > 119:\n",
    "                    normalized_df = normalized_df.iloc[:119]\n",
    "                elif len(normalized_df) < 119:\n",
    "                    # íŒ¨ë”© (ë§ˆì§€ë§‰ ê°’ìœ¼ë¡œ ì±„ìš°ê¸°)\n",
    "                    last_row = normalized_df.iloc[-1]\n",
    "                    padding_rows = 119 - len(normalized_df)\n",
    "                    padding_df = pd.DataFrame([last_row] * padding_rows)\n",
    "                    normalized_df = pd.concat([normalized_df, padding_df], ignore_index=True)\n",
    "                \n",
    "                all_data.append(normalized_df.values)\n",
    "                all_labels.append(one_hot_label)\n",
    "    \n",
    "    # NumPy ë°°ì—´ë¡œ ë³€í™˜\n",
    "    X = np.array(all_data)\n",
    "    y = np.array(all_labels)\n",
    "    \n",
    "    print(f\"\\nì²˜ë¦¬ëœ ë°ì´í„° í˜•íƒœ: {X.shape}, {y.shape}\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# ë°ì´í„° ì²˜ë¦¬ ì‹¤í–‰\n",
    "X, y = process_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í›ˆë ¨ ë°ì´í„°: (108, 119, 6)\n",
      "ê²€ì¦ ë°ì´í„°: (23, 119, 6)\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°: (23, 119, 6)\n"
     ]
    }
   ],
   "source": [
    "# sklearn ì—†ì´ ì§ì ‘ êµ¬í˜„í•œ train_test_split\n",
    "def custom_train_test_split(X, y, test_size=0.2, val_size=0.1, random_state=None):\n",
    "    \"\"\"\n",
    "    sklearn ì—†ì´ ì§ì ‘ êµ¬í˜„í•œ ë°ì´í„° ë¶„í•  í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    n_samples = len(X)\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¶„í• \n",
    "    test_split = int(n_samples * test_size)\n",
    "    test_indices = indices[:test_split]\n",
    "    remaining_indices = indices[test_split:]\n",
    "    \n",
    "    # ê²€ì¦ ì„¸íŠ¸ ë¶„í• \n",
    "    val_split = int(len(remaining_indices) * val_size / (1 - test_size))\n",
    "    val_indices = remaining_indices[:val_split]\n",
    "    train_indices = remaining_indices[val_split:]\n",
    "    \n",
    "    return (X[train_indices], X[val_indices], X[test_indices],\n",
    "            y[train_indices], y[val_indices], y[test_indices])\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "inputs_train, inputs_val, inputs_test, outputs_train, outputs_val, outputs_test = custom_train_test_split(\n",
    "    X, y, test_size=0.15, val_size=0.15, random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"í›ˆë ¨ ë°ì´í„°: {inputs_train.shape}\")\n",
    "print(f\"ê²€ì¦ ë°ì´í„°: {inputs_val.shape}\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {inputs_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ðŸš€ ê°œì„ ëœ ëª¨ë¸ ì„¤ê³„ ë° í•™ìŠµ\n",
    "\n",
    "ì–‘ìží™”ì— ìµœì í™”ëœ TinyML ëª¨ë¸ì„ ì„¤ê³„í•˜ê³  í•™ìŠµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ ì–‘ìží™” ìµœì í™” ëª¨ë¸ ìƒì„± ì¤‘...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 117, 8)            152       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 117, 8)            32        \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 58, 8)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 58, 8)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 54, 16)            656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 54, 16)            64        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 27, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 27, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 21, 32)            3616      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 21, 32)            128       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 5,227\n",
      "Trainable params: 5,115\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "\n",
      "ðŸ”§ ì´ˆê°„ë‹¨ ëª¨ë¸ë„ ì¤€ë¹„...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 117, 8)            152       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 29, 8)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 29, 8)             0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 179\n",
      "Trainable params: 179\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_quantization_friendly_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    ì–‘ìží™”ì— ìµœì í™”ëœ ëª¨ë¸ êµ¬ì¡°\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        # ë” ì•ˆì •ì ì¸ êµ¬ì¡°ë¡œ ë³€ê²½\n",
    "        tf.keras.layers.Conv1D(8, 3, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling1D(2),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(16, 5, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling1D(2),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(32, 7, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),  # Flatten ëŒ€ì‹  GAP\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        # ë” ìž‘ì€ Dense ë ˆì´ì–´\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_ultra_simple_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    ì–‘ìží™”ì— ë§¤ìš° ì•ˆì „í•œ ì´ˆê°„ë‹¨ ëª¨ë¸\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv1D(8, 3, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPooling1D(4),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ëª¨ë¸ ìƒì„±\n",
    "input_shape = (119, 6)  # (ì‹œí€€ìŠ¤ ê¸¸ì´, íŠ¹ì„± ìˆ˜)\n",
    "num_classes = 3\n",
    "\n",
    "print(\"ðŸ”§ ì–‘ìží™” ìµœì í™” ëª¨ë¸ ìƒì„± ì¤‘...\")\n",
    "model = create_quantization_friendly_model(input_shape, num_classes)\n",
    "model.summary()\n",
    "\n",
    "print(\"\\nðŸ”§ ì´ˆê°„ë‹¨ ëª¨ë¸ë„ ì¤€ë¹„...\")\n",
    "simple_model = create_ultra_simple_model(input_shape, num_classes)\n",
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ ëª¨ë¸ í•™ìŠµ ì‹œìž‘...\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 1s 26ms/step - loss: 0.7599 - accuracy: 0.7130 - val_loss: 1.0699 - val_accuracy: 0.6522\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65217, saving model to ./IMU\\best_model.keras\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5819 - accuracy: 0.7407 - val_loss: 1.0411 - val_accuracy: 0.7391\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.65217 to 0.73913, saving model to ./IMU\\best_model.keras\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.8148 - val_loss: 1.0419 - val_accuracy: 0.7391\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.73913\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.9074 - val_loss: 1.0452 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.73913\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2725 - accuracy: 0.9537 - val_loss: 1.0390 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73913\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2112 - accuracy: 0.9537 - val_loss: 1.0348 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.73913\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1878 - accuracy: 0.9630 - val_loss: 1.0232 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.73913\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1600 - accuracy: 0.9722 - val_loss: 1.0179 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.73913\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0917 - accuracy: 0.9815 - val_loss: 1.0245 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.73913\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0923 - accuracy: 0.9815 - val_loss: 1.0475 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.73913\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 1.0743 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.73913\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 1.0636 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.73913\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 1.0408 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.73913\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 1.0308 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.73913\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0347 - accuracy: 0.9907 - val_loss: 1.0438 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.73913\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0479 - accuracy: 0.9907 - val_loss: 1.0489 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.73913\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.9815 - val_loss: 0.9898 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.73913\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9907 - val_loss: 0.9142 - val_accuracy: 0.6087\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.73913\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.8451 - val_accuracy: 0.7391\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.73913\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.8183 - val_accuracy: 0.7391\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.73913\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.8138 - val_accuracy: 0.7391\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.73913\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.8799 - val_accuracy: 0.4348\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.73913\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 0.9815 - val_loss: 0.9475 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.73913\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.1286 - val_accuracy: 0.3478\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.73913\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0499 - accuracy: 0.9815 - val_loss: 0.6130 - val_accuracy: 0.7391\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.73913\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.5138 - val_accuracy: 0.7391\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.73913\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.4556 - val_accuracy: 0.7391\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.73913\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.4079 - val_accuracy: 0.7826\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.73913 to 0.78261, saving model to ./IMU\\best_model.keras\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.3665 - val_accuracy: 0.8261\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.78261 to 0.82609, saving model to ./IMU\\best_model.keras\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.3297 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.82609 to 0.91304, saving model to ./IMU\\best_model.keras\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.9815 - val_loss: 0.3348 - val_accuracy: 0.9565\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.91304 to 0.95652, saving model to ./IMU\\best_model.keras\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4591 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.95652\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.5100 - val_accuracy: 0.7826\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.95652\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.4837 - val_accuracy: 0.8696\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.95652\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 0.9907 - val_loss: 0.4193 - val_accuracy: 0.9565\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.95652\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.3433 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.95652 to 1.00000, saving model to ./IMU\\best_model.keras\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.2715 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 1.00000\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9907 - val_loss: 0.1526 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 1.00000\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 1.00000\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 1.00000\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 1.00000\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 1.00000\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 1.00000\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0612 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 1.00000\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 1.00000\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0350 - accuracy: 0.9907 - val_loss: 0.0554 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 1.00000\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 1.00000\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 1.00000\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0561 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 1.00000\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 1.00000\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 1.00000\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 1.00000\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 1.00000\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9907 - val_loss: 0.0356 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 1.00000\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 1.00000\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.0326 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 1.00000\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 1.00000\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0352 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 1.00000\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 1.00000\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 1.00000\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 1.00000\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9815 - val_loss: 0.0387 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 1.00000\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 0.9565\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 1.00000\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.8696\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 1.00000\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.8261\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 1.00000\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.8261\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 1.00000\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2862 - val_accuracy: 0.8696\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 1.00000\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.8696\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 1.00000\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 1.00000\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 1.00000\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 1.00000\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 1.00000\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 1.00000\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 1.00000\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 1.00000\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 1.00000\n",
      "âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ì½œë°± ì„¤ì •\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=40,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ì €ìž¥ ê²½ë¡œ (ì‚¬ìš©ìž ì§€ì • ê²½ë¡œ)\n",
    "model_save_path = os.path.join(DATA_ROOT, 'best_model.keras')\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ\n",
    "print(\"ðŸš€ ëª¨ë¸ í•™ìŠµ ì‹œìž‘...\")\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "history = model.fit(\n",
    "    inputs_train,\n",
    "    outputs_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(inputs_val, outputs_val),\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€...\n",
      "\n",
      "âœ… Float32 ëª¨ë¸ ì •í™•ë„: 1.0000 (100.00%)\n",
      "\n",
      "ë¶„ë¥˜ ë¦¬í¬íŠ¸:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ë‚ ë‹¤       1.00      1.00      1.00        12\n",
      "          ì•‰ë‹¤       1.00      1.00      1.00         4\n",
      "          ëŒë‹¤       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        23\n",
      "   macro avg       1.00      1.00      1.00        23\n",
      "weighted avg       1.00      1.00      1.00        23\n",
      "\n",
      "\n",
      "í˜¼ë™ í–‰ë ¬:\n",
      "[[12  0  0]\n",
      " [ 0  4  0]\n",
      " [ 0  0  7]]\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ í‰ê°€\n",
    "print(\"ðŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€...\")\n",
    "pred = model.predict(inputs_test)\n",
    "pred_labels = np.argmax(pred, axis=1)\n",
    "true_labels = np.argmax(outputs_test, axis=1)\n",
    "\n",
    "float32_accuracy = np.mean(pred_labels == true_labels)\n",
    "print(f\"\\nâœ… Float32 ëª¨ë¸ ì •í™•ë„: {float32_accuracy:.4f} ({float32_accuracy*100:.2f}%)\")\n",
    "\n",
    "print(\"\\në¶„ë¥˜ ë¦¬í¬íŠ¸:\")\n",
    "print(classification_report(true_labels, pred_labels, target_names=[\"ë‚ ë‹¤\", \"ì•‰ë‹¤\", \"ëŒë‹¤\"]))\n",
    "print(\"\\ní˜¼ë™ í–‰ë ¬:\")\n",
    "print(confusion_matrix(true_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ðŸš€ ê°œì„ ëœ INT8 ì–‘ìží™” ë° ì„±ëŠ¥ ì ê²€\n",
    "\n",
    "ì´ ì„¹ì…˜ì—ì„œëŠ” ì—¬ëŸ¬ ê°€ì§€ ê°œì„ ëœ ì–‘ìží™” ê¸°ë²•ì„ ì‹œë„í•˜ì—¬ ìµœì ì˜ ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì €ìž¥ ë””ë ‰í† ë¦¬: ./tinyml_magicwand-main\\tflite_models\n"
     ]
    }
   ],
   "source": [
    "# ì €ìž¥ ë””ë ‰í† ë¦¬ ìƒì„± (ì‚¬ìš©ìž ì§€ì • ê²½ë¡œ)\n",
    "output_dir = os.path.join('./tinyml_magicwand-main', 'tflite_models')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"ëª¨ë¸ ì €ìž¥ ë””ë ‰í† ë¦¬: {output_dir}\")\n",
    "\n",
    "def convert_to_mixed_precision(model, X_train, model_path):\n",
    "    \"\"\"\n",
    "    í˜¼í•© ì •ë°€ë„ ì–‘ìží™” (ìž…ì¶œë ¥ Float32, ë‚´ë¶€ INT8)\n",
    "    \"\"\"\n",
    "    def representative_data_gen():\n",
    "        print(f\"ëŒ€í‘œ ë°ì´í„° ìƒì„± ì¤‘... ({min(200, len(X_train))}ê°œ ìƒ˜í”Œ)\")\n",
    "        for i in range(min(200, len(X_train))):\n",
    "            yield [X_train[i:i+1].astype(np.float32)]\n",
    "    \n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_data_gen\n",
    "    \n",
    "    # í˜¼í•© ì •ë°€ë„ ì„¤ì • (ìž…ì¶œë ¥ Float32, ë‚´ë¶€ INT8)\n",
    "    converter.target_spec.supported_ops = [\n",
    "        tf.lite.OpsSet.TFLITE_BUILTINS_INT8,\n",
    "        tf.lite.OpsSet.TFLITE_BUILTINS\n",
    "    ]\n",
    "    # ìž…ì¶œë ¥ íƒ€ìž… ì§€ì •í•˜ì§€ ì•ŠìŒ (Float32 ìœ ì§€)\n",
    "    \n",
    "    print(\"í˜¼í•© ì •ë°€ë„ ì–‘ìží™” ë³€í™˜ ì¤‘...\")\n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    with open(model_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    \n",
    "    print(f\"âœ… í˜¼í•© ì •ë°€ë„ ëª¨ë¸ ì €ìž¥ ì™„ë£Œ: {model_path}\")\n",
    "    return tflite_model\n",
    "\n",
    "def enhanced_int8_conversion(model, X_train, y_train, model_path):\n",
    "    \"\"\"\n",
    "    ê°œì„ ëœ INT8 ì–‘ìží™” ë³€í™˜ (í´ëž˜ìŠ¤ë³„ ê· ë“± ìƒ˜í”Œë§)\n",
    "    \"\"\"\n",
    "    def comprehensive_representative_data_gen():\n",
    "        print(\"í¬ê´„ì  ëŒ€í‘œ ë°ì´í„° ìƒì„± ì¤‘... (í´ëž˜ìŠ¤ë³„ ê· ë“± ìƒ˜í”Œë§)\")\n",
    "        \n",
    "        # í´ëž˜ìŠ¤ë³„ ê· ë“± ìƒ˜í”Œë§\n",
    "        samples_per_class = 150  # í´ëž˜ìŠ¤ë‹¹ 150ê°œ\n",
    "        for class_idx in range(3):\n",
    "            class_mask = np.argmax(y_train, axis=1) == class_idx\n",
    "            class_data = X_train[class_mask]\n",
    "            \n",
    "            if len(class_data) > 0:\n",
    "                n_samples = min(samples_per_class, len(class_data))\n",
    "                indices = np.random.choice(len(class_data), n_samples, replace=False)\n",
    "                \n",
    "                for idx in indices:\n",
    "                    yield [class_data[idx:idx+1].astype(np.float32)]\n",
    "    \n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = comprehensive_representative_data_gen\n",
    "    \n",
    "    # ì™„ì „ INT8 ì„¤ì •\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8\n",
    "    converter.inference_output_type = tf.int8\n",
    "    \n",
    "    print(\"ê°œì„ ëœ INT8 ì–‘ìží™” ë³€í™˜ ì¤‘...\")\n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    with open(model_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    \n",
    "    print(f\"âœ… ê°œì„ ëœ INT8 ëª¨ë¸ ì €ìž¥ ì™„ë£Œ: {model_path}\")\n",
    "    return tflite_model\n",
    "\n",
    "def ultra_enhanced_int8_conversion(model, X_train, y_train, model_path):\n",
    "    \"\"\"\n",
    "    ìµœê³  ì„±ëŠ¥ INT8 ì–‘ìží™” ë³€í™˜ (ì „ì²´ í›ˆë ¨ ë°ì´í„° ì‚¬ìš©)\n",
    "    \"\"\"\n",
    "    def ultra_representative_data_gen():\n",
    "        print(\"ìµœê³  ì„±ëŠ¥ ëŒ€í‘œ ë°ì´í„° ìƒì„± ì¤‘... (ì „ì²´ í›ˆë ¨ ë°ì´í„° ì‚¬ìš©)\")\n",
    "        \n",
    "        # ì „ì²´ í›ˆë ¨ ë°ì´í„° ì‚¬ìš©\n",
    "        total_samples = len(X_train)\n",
    "        indices = np.arange(total_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        for idx in indices:\n",
    "            yield [X_train[idx:idx+1].astype(np.float32)]\n",
    "    \n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = ultra_representative_data_gen\n",
    "    \n",
    "    # ì™„ì „ INT8 ì„¤ì •\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8\n",
    "    converter.inference_output_type = tf.int8\n",
    "    \n",
    "    print(\"ìµœê³  ì„±ëŠ¥ INT8 ì–‘ìží™” ë³€í™˜ ì¤‘...\")\n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    with open(model_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    \n",
    "    print(f\"âœ… ìµœê³  ì„±ëŠ¥ INT8 ëª¨ë¸ ì €ìž¥ ì™„ë£Œ: {model_path}\")\n",
    "    return tflite_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_model_check(model_path, X_test, y_test, model_name=\"ëª¨ë¸\"):\n",
    "    \"\"\"\n",
    "    ë¹ ë¥¸ ëª¨ë¸ ì„±ëŠ¥ í™•ì¸\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ” {model_name} ë¹ ë¥¸ ì ê²€\")\n",
    "    \n",
    "    # ëª¨ë¸ í¬ê¸°\n",
    "    size_kb = os.path.getsize(model_path) / 1024\n",
    "    print(f\"ëª¨ë¸ í¬ê¸°: {size_kb:.1f}KB\")\n",
    "    \n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    # íƒ€ìž… í™•ì¸\n",
    "    input_type = input_details[0]['dtype']\n",
    "    output_type = output_details[0]['dtype']\n",
    "    print(f\"ìž…ë ¥ íƒ€ìž…: {input_type}\")\n",
    "    print(f\"ì¶œë ¥ íƒ€ìž…: {output_type}\")\n",
    "    \n",
    "    # ì •í™•ë„ ì¸¡ì •\n",
    "    correct = 0\n",
    "    inference_times = []\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        input_data = X_test[i:i+1].astype(input_type)\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        \n",
    "        # ì¶”ë¡  ì‹œê°„ ì¸¡ì •\n",
    "        start_time = time.time()\n",
    "        interpreter.invoke()\n",
    "        inference_time = time.time() - start_time\n",
    "        inference_times.append(inference_time)\n",
    "        \n",
    "        output = interpreter.get_tensor(output_details[0]['index'])\n",
    "        pred = np.argmax(output[0])\n",
    "        true = np.argmax(y_test[i])\n",
    "        \n",
    "        if pred == true:\n",
    "            correct += 1\n",
    "    \n",
    "    accuracy = correct / len(X_test)\n",
    "    avg_inference_time = np.mean(inference_times) * 1000  # ms\n",
    "    \n",
    "    print(f\"ì •í™•ë„: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_inference_time:.2f}ms\")\n",
    "    \n",
    "    # ì–‘ìží™” íƒ€ìž… í™•ì¸\n",
    "    if input_type == np.int8 and output_type == np.int8:\n",
    "        print(\"âœ… ì™„ì „ INT8 ì–‘ìží™”\")\n",
    "    elif input_type == np.float32 and output_type == np.float32:\n",
    "        print(\"ðŸ“Š Float32 (ë˜ëŠ” í˜¼í•© ì •ë°€ë„)\")\n",
    "    else:\n",
    "        print(f\"ðŸ”„ í˜¼í•© íƒ€ìž…: ìž…ë ¥({input_type}), ì¶œë ¥({output_type})\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'avg_inference_time_ms': avg_inference_time,\n",
    "        'model_size_kb': size_kb,\n",
    "        'input_type': input_type,\n",
    "        'output_type': output_type\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ ë‹¨ê³„ë³„ ì–‘ìží™” ì„±ëŠ¥ ê°œì„  ì‹œìž‘!\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š ê¸°ì¤€ ì„±ëŠ¥ (Float32): 100.00%\n",
      "\n",
      "ðŸ”„ 1ë‹¨ê³„: í˜¼í•© ì •ë°€ë„ ì–‘ìží™”\n",
      "í˜¼í•© ì •ë°€ë„ ì–‘ìží™” ë³€í™˜ ì¤‘...\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmpb_orx8z5\\assets\n",
      "ëŒ€í‘œ ë°ì´í„° ìƒì„± ì¤‘... (108ê°œ ìƒ˜í”Œ)\n",
      "âœ… í˜¼í•© ì •ë°€ë„ ëª¨ë¸ ì €ìž¥ ì™„ë£Œ: ./tinyml_magicwand-main\\tflite_models\\mixed_precision.tflite\n",
      "\n",
      "ðŸ” í˜¼í•© ì •ë°€ë„ ë¹ ë¥¸ ì ê²€\n",
      "ëª¨ë¸ í¬ê¸°: 18.3KB\n",
      "ìž…ë ¥ íƒ€ìž…: <class 'numpy.float32'>\n",
      "ì¶œë ¥ íƒ€ìž…: <class 'numpy.float32'>\n",
      "ì •í™•ë„: 1.0000 (100.00%)\n",
      "í‰ê·  ì¶”ë¡  ì‹œê°„: 0.57ms\n",
      "ðŸ“Š Float32 (ë˜ëŠ” í˜¼í•© ì •ë°€ë„)\n",
      "\n",
      "ðŸŽ¯ 2ë‹¨ê³„: ê°œì„ ëœ INT8 ì–‘ìží™” (í´ëž˜ìŠ¤ë³„ ê· ë“± ìƒ˜í”Œë§)\n",
      "ê°œì„ ëœ INT8 ì–‘ìží™” ë³€í™˜ ì¤‘...\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmpn7u3zz89\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmpn7u3zz89\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í¬ê´„ì  ëŒ€í‘œ ë°ì´í„° ìƒì„± ì¤‘... (í´ëž˜ìŠ¤ë³„ ê· ë“± ìƒ˜í”Œë§)\n",
      "âœ… ê°œì„ ëœ INT8 ëª¨ë¸ ì €ìž¥ ì™„ë£Œ: ./tinyml_magicwand-main\\tflite_models\\enhanced_int8.tflite\n",
      "\n",
      "ðŸ” ê°œì„ ëœ INT8 ë¹ ë¥¸ ì ê²€\n",
      "ëª¨ë¸ í¬ê¸°: 18.1KB\n",
      "ìž…ë ¥ íƒ€ìž…: <class 'numpy.int8'>\n",
      "ì¶œë ¥ íƒ€ìž…: <class 'numpy.int8'>\n",
      "ì •í™•ë„: 0.5217 (52.17%)\n",
      "í‰ê·  ì¶”ë¡  ì‹œê°„: 0.57ms\n",
      "âœ… ì™„ì „ INT8 ì–‘ìží™”\n",
      "\n",
      "ðŸš€ 3ë‹¨ê³„: ìµœê³  ì„±ëŠ¥ INT8 ì–‘ìží™” (ì „ì²´ ë°ì´í„° ì‚¬ìš©)\n",
      "ìµœê³  ì„±ëŠ¥ INT8 ì–‘ìží™” ë³€í™˜ ì¤‘...\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmp8eluywke\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\user\\AppData\\Local\\Temp\\tmp8eluywke\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìµœê³  ì„±ëŠ¥ ëŒ€í‘œ ë°ì´í„° ìƒì„± ì¤‘... (ì „ì²´ í›ˆë ¨ ë°ì´í„° ì‚¬ìš©)\n",
      "âœ… ìµœê³  ì„±ëŠ¥ INT8 ëª¨ë¸ ì €ìž¥ ì™„ë£Œ: ./tinyml_magicwand-main\\tflite_models\\ultra_int8.tflite\n",
      "\n",
      "ðŸ” ìµœê³  ì„±ëŠ¥ INT8 ë¹ ë¥¸ ì ê²€\n",
      "ëª¨ë¸ í¬ê¸°: 18.1KB\n",
      "ìž…ë ¥ íƒ€ìž…: <class 'numpy.int8'>\n",
      "ì¶œë ¥ íƒ€ìž…: <class 'numpy.int8'>\n",
      "ì •í™•ë„: 0.5217 (52.17%)\n",
      "í‰ê·  ì¶”ë¡  ì‹œê°„: 0.66ms\n",
      "âœ… ì™„ì „ INT8 ì–‘ìží™”\n",
      "\n",
      "âš ï¸ 4ë‹¨ê³„: QAT ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ - ê±´ë„ˆëœ€\n",
      "\n",
      "ðŸ”§ 5ë‹¨ê³„: ì´ˆê°„ë‹¨ ëª¨ë¸ë¡œ ìž¬ì‹œë„\n",
      "ì´ˆê°„ë‹¨ ëª¨ë¸ í›ˆë ¨ ì¤‘...\n",
      "ì´ˆê°„ë‹¨ ëª¨ë¸ Float32 ì •í™•ë„: 47.83%\n",
      "\n",
      "============================================================\n",
      "ðŸŽ‰ ì–‘ìží™” ì„±ëŠ¥ ê°œì„  ì™„ë£Œ!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ðŸš€ ë‹¨ê³„ë³„ ì–‘ìží™” ì„±ëŠ¥ ê°œì„  ì‹¤í–‰\n",
    "print(\"ðŸŽ¯ ë‹¨ê³„ë³„ ì–‘ìží™” ì„±ëŠ¥ ê°œì„  ì‹œìž‘!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_summary = {}\n",
    "\n",
    "# Float32 ê¸°ì¤€ ì„±ëŠ¥\n",
    "print(f\"\\nðŸ“Š ê¸°ì¤€ ì„±ëŠ¥ (Float32): {float32_accuracy*100:.2f}%\")\n",
    "results_summary['Float32'] = float32_accuracy\n",
    "\n",
    "# 1ë‹¨ê³„: í˜¼í•© ì •ë°€ë„ ì–‘ìží™”\n",
    "print(\"\\nðŸ”„ 1ë‹¨ê³„: í˜¼í•© ì •ë°€ë„ ì–‘ìží™”\")\n",
    "mixed_precision_path = os.path.join(output_dir, 'mixed_precision.tflite')\n",
    "mixed_model = convert_to_mixed_precision(model, inputs_train, mixed_precision_path)\n",
    "mixed_results = quick_model_check(mixed_precision_path, inputs_test, outputs_test, \"í˜¼í•© ì •ë°€ë„\")\n",
    "results_summary['í˜¼í•© ì •ë°€ë„'] = mixed_results['accuracy']\n",
    "\n",
    "# 2ë‹¨ê³„: ê°œì„ ëœ INT8 ì–‘ìží™”\n",
    "print(\"\\nðŸŽ¯ 2ë‹¨ê³„: ê°œì„ ëœ INT8 ì–‘ìží™” (í´ëž˜ìŠ¤ë³„ ê· ë“± ìƒ˜í”Œë§)\")\n",
    "enhanced_int8_path = os.path.join(output_dir, 'enhanced_int8.tflite')\n",
    "enhanced_model = enhanced_int8_conversion(model, inputs_train, outputs_train, enhanced_int8_path)\n",
    "enhanced_results = quick_model_check(enhanced_int8_path, inputs_test, outputs_test, \"ê°œì„ ëœ INT8\")\n",
    "results_summary['ê°œì„ ëœ INT8'] = enhanced_results['accuracy']\n",
    "\n",
    "# 3ë‹¨ê³„: ìµœê³  ì„±ëŠ¥ INT8 ì–‘ìží™”\n",
    "print(\"\\nðŸš€ 3ë‹¨ê³„: ìµœê³  ì„±ëŠ¥ INT8 ì–‘ìží™” (ì „ì²´ ë°ì´í„° ì‚¬ìš©)\")\n",
    "ultra_int8_path = os.path.join(output_dir, 'ultra_int8.tflite')\n",
    "ultra_model = ultra_enhanced_int8_conversion(model, inputs_train, outputs_train, ultra_int8_path)\n",
    "ultra_results = quick_model_check(ultra_int8_path, inputs_test, outputs_test, \"ìµœê³  ì„±ëŠ¥ INT8\")\n",
    "results_summary['ìµœê³  ì„±ëŠ¥ INT8'] = ultra_results['accuracy']\n",
    "\n",
    "# 4ë‹¨ê³„: QAT ì‹œë„ (ê°€ëŠ¥í•œ ê²½ìš°)\n",
    "if QAT_AVAILABLE:\n",
    "    print(\"\\nâ­ 4ë‹¨ê³„: ì–‘ìží™” ì¸ì‹ í›ˆë ¨(QAT)\")\n",
    "    qat_model = apply_quantization_aware_training(model, inputs_train, outputs_train, inputs_val, outputs_val)\n",
    "    \n",
    "    qat_int8_path = os.path.join(output_dir, 'qat_int8.tflite')\n",
    "    qat_tflite_model = convert_qat_to_int8(qat_model, inputs_train, outputs_train, qat_int8_path)\n",
    "    qat_results = quick_model_check(qat_int8_path, inputs_test, outputs_test, \"QAT INT8\")\n",
    "    results_summary['QAT INT8'] = qat_results['accuracy']\n",
    "else:\n",
    "    print(\"\\nâš ï¸ 4ë‹¨ê³„: QAT ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ - ê±´ë„ˆëœ€\")\n",
    "\n",
    "# 5ë‹¨ê³„: ì´ˆê°„ë‹¨ ëª¨ë¸ë¡œ ì‹œë„ (ì„±ëŠ¥ì´ ë‚®ì„ ë•Œ)\n",
    "best_int8_accuracy = max([results_summary.get('ê°œì„ ëœ INT8', 0), results_summary.get('ìµœê³  ì„±ëŠ¥ INT8', 0)])\n",
    "if best_int8_accuracy < 0.7:  # 70% ë¯¸ë§Œì´ë©´\n",
    "    print(\"\\nðŸ”§ 5ë‹¨ê³„: ì´ˆê°„ë‹¨ ëª¨ë¸ë¡œ ìž¬ì‹œë„\")\n",
    "    \n",
    "    # ì´ˆê°„ë‹¨ ëª¨ë¸ í›ˆë ¨\n",
    "    print(\"ì´ˆê°„ë‹¨ ëª¨ë¸ í›ˆë ¨ ì¤‘...\")\n",
    "    simple_history = simple_model.fit(\n",
    "        inputs_train, outputs_train,\n",
    "        validation_data=(inputs_val, outputs_val),\n",
    "        epochs=50,\n",
    "        batch_size=8,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # ì´ˆê°„ë‹¨ ëª¨ë¸ ì„±ëŠ¥ í™•ì¸\n",
    "    simple_pred = simple_model.predict(inputs_test)\n",
    "    simple_accuracy = np.mean(np.argmax(simple_pred, axis=1) == np.argmax(outputs_test, axis=1))\n",
    "    print(f\"ì´ˆê°„ë‹¨ ëª¨ë¸ Float32 ì •í™•ë„: {simple_accuracy*100:.2f}%\")\n",
    "    \n",
    "    if simple_accuracy > 0.8:  # 80% ì´ìƒì´ë©´\n",
    "        simple_int8_path = os.path.join(output_dir, 'simple_int8.tflite')\n",
    "        simple_int8_model = ultra_enhanced_int8_conversion(simple_model, inputs_train, outputs_train, simple_int8_path)\n",
    "        simple_results = quick_model_check(simple_int8_path, inputs_test, outputs_test, \"ì´ˆê°„ë‹¨ INT8\")\n",
    "        results_summary['ì´ˆê°„ë‹¨ INT8'] = simple_results['accuracy']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ‰ ì–‘ìží™” ì„±ëŠ¥ ê°œì„  ì™„ë£Œ!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š ìµœì¢… ì„±ëŠ¥ ë¹„êµ:\n",
      "----------------------------------------\n",
      "Float32        : 100.00%\n",
      "í˜¼í•© ì •ë°€ë„         : 100.00%\n",
      "ê°œì„ ëœ INT8       :  52.17%\n",
      "ìµœê³  ì„±ëŠ¥ INT8     :  52.17%\n",
      "----------------------------------------\n",
      "\n",
      "ðŸ† ìµœê³  ì„±ëŠ¥ INT8 ëª¨ë¸: ê°œì„ ëœ INT8\n",
      "   ì •í™•ë„: 52.17%\n",
      "   íŒŒì¼: ./tinyml_magicwand-main\\tflite_models\\enhanced_int8.tflite\n",
      "   âœ… ìµœì  ëª¨ë¸ ë³µì‚¬: ./tinyml_magicwand-main\\tflite_models\\gesture_model_int8_best.tflite\n",
      "\n",
      "ðŸ“ˆ ì„±ëŠ¥ ê°œì„  ìš”ì•½:\n",
      "   ì›ëž˜ INT8 ì„±ëŠ¥: ~17%\n",
      "   ê°œì„ ëœ ì„±ëŠ¥: 52.17%\n",
      "   ê°œì„ ë„: +35.2%p\n",
      "   âš ï¸ ì¶”ê°€ ê°œì„  í•„ìš”\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Š ìµœì¢… ê²°ê³¼ ë¹„êµ ë° ìµœì  ëª¨ë¸ ì„ íƒ\n",
    "print(\"\\nðŸ“Š ìµœì¢… ì„±ëŠ¥ ë¹„êµ:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "best_model_name = \"\"\n",
    "best_accuracy = 0\n",
    "best_model_path = \"\"\n",
    "\n",
    "for model_name, accuracy in results_summary.items():\n",
    "    print(f\"{model_name:15}: {accuracy*100:6.2f}%\")\n",
    "    \n",
    "    # INT8 ëª¨ë¸ ì¤‘ ìµœê³  ì„±ëŠ¥ ì°¾ê¸°\n",
    "    if 'INT8' in model_name and accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model_name = model_name\n",
    "        \n",
    "        # ëª¨ë¸ ê²½ë¡œ ë§¤í•‘\n",
    "        if model_name == 'ê°œì„ ëœ INT8':\n",
    "            best_model_path = enhanced_int8_path\n",
    "        elif model_name == 'ìµœê³  ì„±ëŠ¥ INT8':\n",
    "            best_model_path = ultra_int8_path\n",
    "        elif model_name == 'QAT INT8':\n",
    "            best_model_path = qat_int8_path\n",
    "        elif model_name == 'ì´ˆê°„ë‹¨ INT8':\n",
    "            best_model_path = simple_int8_path\n",
    "\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# ìµœì  ëª¨ë¸ ì •ë³´\n",
    "if best_model_name:\n",
    "    print(f\"\\nðŸ† ìµœê³  ì„±ëŠ¥ INT8 ëª¨ë¸: {best_model_name}\")\n",
    "    print(f\"   ì •í™•ë„: {best_accuracy*100:.2f}%\")\n",
    "    print(f\"   íŒŒì¼: {best_model_path}\")\n",
    "    \n",
    "    # ìµœì  ëª¨ë¸ì„ ë©”ì¸ ëª¨ë¸ë¡œ ë³µì‚¬\n",
    "    main_model_path = os.path.join(output_dir, 'gesture_model_int8_best.tflite')\n",
    "    import shutil\n",
    "    shutil.copy2(best_model_path, main_model_path)\n",
    "    print(f\"   âœ… ìµœì  ëª¨ë¸ ë³µì‚¬: {main_model_path}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ INT8 ëª¨ë¸ ì„±ëŠ¥ì´ ëª¨ë‘ ë‚®ìŠµë‹ˆë‹¤. í˜¼í•© ì •ë°€ë„ ëª¨ë¸ ì‚¬ìš©ì„ ê¶Œìž¥í•©ë‹ˆë‹¤.\")\n",
    "    main_model_path = mixed_precision_path\n",
    "\n",
    "# ì„±ëŠ¥ ê°œì„  ìš”ì•½\n",
    "original_int8_accuracy = 0.17  # ì›ëž˜ ì„±ëŠ¥ (ì˜ˆì‹œ)\n",
    "improvement = (best_accuracy - original_int8_accuracy) * 100\n",
    "\n",
    "print(f\"\\nðŸ“ˆ ì„±ëŠ¥ ê°œì„  ìš”ì•½:\")\n",
    "print(f\"   ì›ëž˜ INT8 ì„±ëŠ¥: ~17%\")\n",
    "print(f\"   ê°œì„ ëœ ì„±ëŠ¥: {best_accuracy*100:.2f}%\")\n",
    "print(f\"   ê°œì„ ë„: +{improvement:.1f}%p\")\n",
    "\n",
    "if best_accuracy > 0.8:\n",
    "    print(\"   ðŸŽ‰ ì‹¤ìš©ì  ìˆ˜ì¤€ ë‹¬ì„±!\")\n",
    "elif best_accuracy > 0.6:\n",
    "    print(\"   âœ… ìƒë‹¹í•œ ê°œì„  ë‹¬ì„±!\")\n",
    "else:\n",
    "    print(\"   âš ï¸ ì¶”ê°€ ê°œì„  í•„ìš”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Arduino ë°°í¬ ê°€ì´ë“œ\n",
    "\n",
    "ìµœì í™”ëœ TFLite ëª¨ë¸ì„ Arduinoì— ë°°í¬í•˜ê¸° ìœ„í•œ ê°€ì´ë“œìž…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Arduino í—¤ë” íŒŒì¼ ìƒì„± ì™„ë£Œ: ./tinyml_magicwand-main\\tflite_models\\gesture_model.h\n",
      "   ëª¨ë¸ í¬ê¸°: 18512 bytes\n"
     ]
    }
   ],
   "source": [
    "def generate_arduino_header(model_path, header_path):\n",
    "    \"\"\"\n",
    "    TFLite ëª¨ë¸ì„ Arduinoìš© C++ í—¤ë” íŒŒì¼ë¡œ ë³€í™˜\n",
    "    \"\"\"\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model_data = f.read()\n",
    "    \n",
    "    header_content = f\"\"\"// ìžë™ ìƒì„±ëœ TensorFlow Lite ëª¨ë¸ í—¤ë” íŒŒì¼\n",
    "// ëª¨ë¸ í¬ê¸°: {len(model_data)} bytes\n",
    "// ìµœì í™”: {best_model_name if best_model_name else 'í˜¼í•© ì •ë°€ë„'}\n",
    "// ì •í™•ë„: {best_accuracy*100:.2f}%\n",
    "\n",
    "#ifndef GESTURE_MODEL_H\n",
    "#define GESTURE_MODEL_H\n",
    "\n",
    "const unsigned char gesture_model_tflite[] = {{\n",
    "\"\"\"\n",
    "    \n",
    "    # ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ 16ì§„ìˆ˜ë¡œ ë³€í™˜\n",
    "    for i, byte in enumerate(model_data):\n",
    "        if i % 16 == 0:\n",
    "            header_content += \"\\n  \"\n",
    "        header_content += f\"0x{byte:02x}\"\n",
    "        if i < len(model_data) - 1:\n",
    "            header_content += \", \"\n",
    "    \n",
    "    header_content += f\"\"\"\n",
    "}};\n",
    "\n",
    "const unsigned int gesture_model_tflite_len = {len(model_data)};\n",
    "\n",
    "#endif  // GESTURE_MODEL_H\n",
    "\"\"\"\n",
    "    \n",
    "    with open(header_path, 'w') as f:\n",
    "        f.write(header_content)\n",
    "    \n",
    "    print(f\"âœ… Arduino í—¤ë” íŒŒì¼ ìƒì„± ì™„ë£Œ: {header_path}\")\n",
    "    print(f\"   ëª¨ë¸ í¬ê¸°: {len(model_data)} bytes\")\n",
    "    return len(model_data)\n",
    "\n",
    "# Arduino í—¤ë” íŒŒì¼ ìƒì„±\n",
    "header_path = os.path.join(output_dir, 'gesture_model.h')\n",
    "model_size_bytes = generate_arduino_header(main_model_path, header_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ 3ê°œ ëª¨ë¸ì„ C++ í—¤ë” íŒŒì¼ë¡œ ë³€í™˜ ì¤‘...\n",
      "============================================================\n",
      "\\nðŸ“„ í˜¼í•© ì •ë°€ë„ ëª¨ë¸ ë³€í™˜ ì¤‘...\n",
      "âœ… í˜¼í•© ì •ë°€ë„ ëª¨ë¸ í—¤ë” íŒŒì¼ ìƒì„± ì™„ë£Œ: C:/Users/user/Desktop/tinyml_magicwand-main/tflite_models\\gesture_model_mixed.h\n",
      "   ëª¨ë¸ í¬ê¸°: 18704 bytes (18.3KB)\n",
      "   ì •í™•ë„: 100.00%\n",
      "\\nðŸ“„ ê°œì„ ëœ INT8 ëª¨ë¸ ë³€í™˜ ì¤‘...\n",
      "âœ… ê°œì„ ëœ INT8 ëª¨ë¸ í—¤ë” íŒŒì¼ ìƒì„± ì™„ë£Œ: C:/Users/user/Desktop/tinyml_magicwand-main/tflite_models\\gesture_model_int8.h\n",
      "   ëª¨ë¸ í¬ê¸°: 18512 bytes (18.1KB)\n",
      "   ì •í™•ë„: 52.17%\n",
      "\\nðŸ“„ ì´ˆê°„ë‹¨ INT8 ëª¨ë¸ ë³€í™˜ ì¤‘...\n",
      "âœ… ì´ˆê°„ë‹¨ INT8 ëª¨ë¸ í—¤ë” íŒŒì¼ ìƒì„± ì™„ë£Œ: C:/Users/user/Desktop/tinyml_magicwand-main/tflite_models\\gesture_model_ultra.h\n",
      "   ëª¨ë¸ í¬ê¸°: 18512 bytes (18.1KB)\n",
      "   ì •í™•ë„: 17.39%\n",
      "\\n============================================================\n",
      "ðŸŽ‰ ëª¨ë“  ëª¨ë¸ ë³€í™˜ ì™„ë£Œ!\n",
      "============================================================\n",
      "\\nðŸ“Š ìƒì„±ëœ í—¤ë” íŒŒì¼ ìš”ì•½:\n",
      "--------------------------------------------------\n",
      "í˜¼í•© ì •ë°€ë„ ëª¨ë¸           : gesture_model_mixed.h\n",
      "                      í¬ê¸°: 18.3KB\n",
      "                      ì •í™•ë„: 100.00%\n",
      "\n",
      "ê°œì„ ëœ INT8 ëª¨ë¸         : gesture_model_int8.h\n",
      "                      í¬ê¸°: 18.1KB\n",
      "                      ì •í™•ë„: 52.17%\n",
      "\n",
      "ì´ˆê°„ë‹¨ INT8 ëª¨ë¸         : gesture_model_ultra.h\n",
      "                      í¬ê¸°: 18.1KB\n",
      "                      ì •í™•ë„: 17.39%\n",
      "\n",
      "ðŸ“ ëª¨ë“  íŒŒì¼ ìœ„ì¹˜:\n",
      "   C:/Users/user/Desktop/tinyml_magicwand-main/tflite_models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def generate_arduino_header_multi(model_path, header_path, model_name, accuracy, model_type):\n",
    "    \"\"\"\n",
    "    TFLite ëª¨ë¸ì„ Arduinoìš© C++ í—¤ë” íŒŒì¼ë¡œ ë³€í™˜ (ê°œì„ ëœ ë²„ì „)\n",
    "    \"\"\"\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model_data = f.read()\n",
    "    \n",
    "    # ë³€ìˆ˜ëª…ì„ ëª¨ë¸ íƒ€ìž…ì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì„¤ì •\n",
    "    var_name = f\"gesture_model_{model_type.lower()}_tflite\"\n",
    "    len_name = f\"gesture_model_{model_type.lower()}_tflite_len\"\n",
    "    \n",
    "    header_content = f\"\"\"// ìžë™ ìƒì„±ëœ TensorFlow Lite ëª¨ë¸ í—¤ë” íŒŒì¼\n",
    "// ëª¨ë¸ëª…: {model_name}\n",
    "// ëª¨ë¸ íƒ€ìž…: {model_type}\n",
    "// ëª¨ë¸ í¬ê¸°: {len(model_data)} bytes ({len(model_data)/1024:.1f}KB)\n",
    "// ì •í™•ë„: {accuracy:.2f}%\n",
    "// ìƒì„±ì¼: {time.strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "\n",
    "#ifndef GESTURE_MODEL_{model_type.upper()}_H\n",
    "#define GESTURE_MODEL_{model_type.upper()}_H\n",
    "\n",
    "const unsigned char {var_name}[] = {{\n",
    "\"\"\"\n",
    "    \n",
    "    # ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ 16ì§„ìˆ˜ë¡œ ë³€í™˜\n",
    "    for i, byte in enumerate(model_data):\n",
    "        if i % 16 == 0:\n",
    "            header_content += \"\\n  \"\n",
    "        header_content += f\"0x{byte:02x}\"\n",
    "        if i < len(model_data) - 1:\n",
    "            header_content += \", \"\n",
    "    \n",
    "    header_content += f\"\"\"\n",
    "}};\n",
    "\n",
    "const unsigned int {len_name} = {len(model_data)};\n",
    "\n",
    "#endif  // GESTURE_MODEL_{model_type.upper()}_H\n",
    "\"\"\"\n",
    "    \n",
    "    with open(header_path, 'w') as f:\n",
    "        f.write(header_content)\n",
    "    \n",
    "    print(f\"âœ… {model_name} í—¤ë” íŒŒì¼ ìƒì„± ì™„ë£Œ: {header_path}\")\n",
    "    print(f\"   ëª¨ë¸ í¬ê¸°: {len(model_data)} bytes ({len(model_data)/1024:.1f}KB)\")\n",
    "    print(f\"   ì •í™•ë„: {accuracy:.2f}%\")\n",
    "    \n",
    "    return len(model_data)\n",
    "\n",
    "# ðŸŽ¯ 3ê°œ ëª¨ë¸ ì •ë³´ ì •ì˜\n",
    "models_info = [\n",
    "    {\n",
    "        'name': 'í˜¼í•© ì •ë°€ë„ ëª¨ë¸',\n",
    "        'path': './tflite_models/mixed_precision.tflite',\n",
    "        'accuracy': 100.00,\n",
    "        'type': 'MIXED',\n",
    "        'header_name': 'gesture_model_mixed.h'\n",
    "    },\n",
    "    {\n",
    "        'name': 'ê°œì„ ëœ INT8 ëª¨ë¸', \n",
    "        'path': './tflite_models/enhanced_int8.tflite',\n",
    "        'accuracy': 52.17,\n",
    "        'type': 'INT8',\n",
    "        'header_name': 'gesture_model_int8.h'\n",
    "    },\n",
    "    {\n",
    "        'name': 'ì´ˆê°„ë‹¨ INT8 ëª¨ë¸',\n",
    "        'path': './tflite_models/ultra_int8.tflite', \n",
    "        'accuracy': 17.39,\n",
    "        'type': 'SIMPLE',\n",
    "        'header_name': 'gesture_model_ultra.h'\n",
    "    }\n",
    "]\n",
    "\n",
    "# ðŸš€ ëª¨ë“  ëª¨ë¸ì„ C++ í—¤ë”ë¡œ ë³€í™˜\n",
    "print(\"ðŸ”§ 3ê°œ ëª¨ë¸ì„ C++ í—¤ë” íŒŒì¼ë¡œ ë³€í™˜ ì¤‘...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "output_dir = 'C:/Users/user/Desktop/tinyml_magicwand-main/tflite_models'\n",
    "model_sizes = {}\n",
    "\n",
    "for model_info in models_info:\n",
    "    print(f\"\\\\nðŸ“„ {model_info['name']} ë³€í™˜ ì¤‘...\")\n",
    "    \n",
    "    model_path = model_info['path']\n",
    "    header_path = os.path.join(output_dir, model_info['header_name'])\n",
    "    \n",
    "    # íŒŒì¼ ì¡´ìž¬ í™•ì¸\n",
    "    if os.path.exists(model_path):\n",
    "        size = generate_arduino_header_multi(\n",
    "            model_path=model_path,\n",
    "            header_path=header_path,\n",
    "            model_name=model_info['name'],\n",
    "            accuracy=model_info['accuracy'],\n",
    "            model_type=model_info['type']\n",
    "        )\n",
    "        model_sizes[model_info['name']] = size\n",
    "    else:\n",
    "        print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\" * 60)\n",
    "print(\"ðŸŽ‰ ëª¨ë“  ëª¨ë¸ ë³€í™˜ ì™„ë£Œ!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ðŸ“Š ê²°ê³¼ ìš”ì•½\n",
    "print(\"\\\\nðŸ“Š ìƒì„±ëœ í—¤ë” íŒŒì¼ ìš”ì•½:\")\n",
    "print(\"-\" * 50)\n",
    "for model_info in models_info:\n",
    "    if model_info['name'] in model_sizes:\n",
    "        print(f\"{model_info['name']:20}: {model_info['header_name']}\")\n",
    "        print(f\"{'':20}  í¬ê¸°: {model_sizes[model_info['name']]/1024:.1f}KB\")\n",
    "        print(f\"{'':20}  ì •í™•ë„: {model_info['accuracy']:.2f}%\")\n",
    "        print()\n",
    "\n",
    "print(\"ðŸ“ ëª¨ë“  íŒŒì¼ ìœ„ì¹˜:\")\n",
    "print(f\"   {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸŽ‰ ì œìŠ¤ì²˜ ì¸ì‹ TinyML íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! (ê°œì„ ëœ ë²„ì „)\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ ìƒì„±ëœ íŒŒì¼ë“¤ (ê²½ë¡œ: C:/Users/user/Desktop/tinyml_magicwand-main/tflite_models):\n",
      "   ðŸ“„ gesture_model_int8_best.tflite - ìµœì  INT8 ëª¨ë¸\n",
      "   ðŸ“„ mixed_precision.tflite - í˜¼í•© ì •ë°€ë„ ëª¨ë¸\n",
      "   ðŸ“„ gesture_model.h - Arduino í—¤ë” íŒŒì¼\n",
      "   ðŸ“„ gesture_recognition_improved.ino - ê°œì„ ëœ Arduino ì½”ë“œ\n",
      "   ðŸ“„ deployment_guide_improved.md - ìƒì„¸ ë°°í¬ ê°€ì´ë“œ\n",
      "\n",
      "ðŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸:\n",
      "   ðŸŽ¯ ëª¨ë¸: ê°œì„ ëœ INT8\n",
      "   ðŸ“Š ì •í™•ë„: 0.5217 (52.17%)\n",
      "   ðŸ’¾ í¬ê¸°: 18.1KB\n",
      "   âš¡ ë©”ëª¨ë¦¬: 36.2KB\n",
      "\n",
      "ðŸ“ˆ ì„±ëŠ¥ ê°œì„  ìš”ì•½:\n",
      "   ì›ëž˜ ì„±ëŠ¥: ~17%\n",
      "   ê°œì„ ëœ ì„±ëŠ¥: 52.17%\n",
      "   ê°œì„ ë„: +35.2%p\n",
      "   ìƒíƒœ: âš ï¸ í˜¼í•© ì •ë°€ë„ ëª¨ë¸ ì‚¬ìš© ê¶Œìž¥\n",
      "\n",
      "ðŸš€ ë‹¤ìŒ ë‹¨ê³„:\n",
      "   1. Arduino IDEì—ì„œ gesture_recognition_improved.ino ì—´ê¸°\n",
      "   2. gesture_model.h íŒŒì¼ì„ ê°™ì€ í´ë”ì— ë³µì‚¬\n",
      "   3. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (LSM9DS1, TensorFlowLite)\n",
      "   4. Arduino Nano 33 BLEì— ì—…ë¡œë“œ\n",
      "   5. ì‹œë¦¬ì–¼ ëª¨ë‹ˆí„°ì—ì„œ í…ŒìŠ¤íŠ¸ ('s' ìž…ë ¥)\n",
      "\n",
      "ðŸ’¡ ê¶Œìž¥ì‚¬í•­:\n",
      "   ðŸ“Š í˜¼í•© ì •ë°€ë„ ëª¨ë¸ ì‚¬ìš© ê¶Œìž¥ - ë†’ì€ ì •í™•ë„\n",
      "   ðŸŽ¯ ì œìŠ¤ì²˜ë¥¼ í¬ê³  ëª…í™•í•˜ê²Œ ìˆ˜í–‰í•˜ì„¸ìš”\n",
      "   ðŸ“– ìƒì„¸í•œ ì‚¬ìš©ë²•ì€ deployment_guide_improved.md ì°¸ì¡°\n",
      "\n",
      "âœ¨ ê°œì„ ëœ TinyML ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "   ë°ì´í„° ê²½ë¡œ: ./IMU\n",
      "   ëª¨ë¸ ê²½ë¡œ: C:/Users/user/Desktop/tinyml_magicwand-main/tflite_models\n"
     ]
    }
   ],
   "source": [
    "# ðŸŽ‰ ìµœì¢… ìš”ì•½ ë° íŒŒì¼ ëª©ë¡\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸŽ‰ ì œìŠ¤ì²˜ ì¸ì‹ TinyML íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! (ê°œì„ ëœ ë²„ì „)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nðŸ“ ìƒì„±ëœ íŒŒì¼ë“¤ (ê²½ë¡œ: {output_dir}):\")\n",
    "print(f\"   ðŸ“„ gesture_model_int8_best.tflite - ìµœì  INT8 ëª¨ë¸\")\n",
    "print(f\"   ðŸ“„ mixed_precision.tflite - í˜¼í•© ì •ë°€ë„ ëª¨ë¸\")\n",
    "print(f\"   ðŸ“„ gesture_model.h - Arduino í—¤ë” íŒŒì¼\")\n",
    "print(f\"   ðŸ“„ gesture_recognition_improved.ino - ê°œì„ ëœ Arduino ì½”ë“œ\")\n",
    "print(f\"   ðŸ“„ deployment_guide_improved.md - ìƒì„¸ ë°°í¬ ê°€ì´ë“œ\")\n",
    "\n",
    "if best_model_name:\n",
    "    print(f\"\\nðŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸:\")\n",
    "    print(f\"   ðŸŽ¯ ëª¨ë¸: {best_model_name}\")\n",
    "    print(f\"   ðŸ“Š ì •í™•ë„: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")\n",
    "    print(f\"   ðŸ’¾ í¬ê¸°: {model_size_bytes/1024:.1f}KB\")\n",
    "    print(f\"   âš¡ ë©”ëª¨ë¦¬: {max(8192, model_size_bytes * 2)/1024:.1f}KB\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ ì„±ëŠ¥ ê°œì„  ìš”ì•½:\")\n",
    "improvement = (best_accuracy - 0.17) * 100  # ì›ëž˜ 17%ì—ì„œ ê°œì„ \n",
    "print(f\"   ì›ëž˜ ì„±ëŠ¥: ~17%\")\n",
    "print(f\"   ê°œì„ ëœ ì„±ëŠ¥: {best_accuracy*100:.2f}%\")\n",
    "print(f\"   ê°œì„ ë„: +{improvement:.1f}%p\")\n",
    "\n",
    "if best_accuracy > 0.8:\n",
    "    status = \"ðŸŽ‰ ì‹¤ìš©ì  ìˆ˜ì¤€ ë‹¬ì„±!\"\n",
    "elif best_accuracy > 0.6:\n",
    "    status = \"âœ… ìƒë‹¹í•œ ê°œì„  ë‹¬ì„±!\"\n",
    "else:\n",
    "    status = \"âš ï¸ í˜¼í•© ì •ë°€ë„ ëª¨ë¸ ì‚¬ìš© ê¶Œìž¥\"\n",
    "\n",
    "print(f\"   ìƒíƒœ: {status}\")\n",
    "\n",
    "print(f\"\\nðŸš€ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(f\"   1. Arduino IDEì—ì„œ gesture_recognition_improved.ino ì—´ê¸°\")\n",
    "print(f\"   2. gesture_model.h íŒŒì¼ì„ ê°™ì€ í´ë”ì— ë³µì‚¬\")\n",
    "print(f\"   3. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (LSM9DS1, TensorFlowLite)\")\n",
    "print(f\"   4. Arduino Nano 33 BLEì— ì—…ë¡œë“œ\")\n",
    "print(f\"   5. ì‹œë¦¬ì–¼ ëª¨ë‹ˆí„°ì—ì„œ í…ŒìŠ¤íŠ¸ ('s' ìž…ë ¥)\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ ê¶Œìž¥ì‚¬í•­:\")\n",
    "if best_accuracy > 0.7:\n",
    "    print(f\"   âœ… INT8 ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ - ìµœê³  íš¨ìœ¨ì„±\")\n",
    "else:\n",
    "    print(f\"   ðŸ“Š í˜¼í•© ì •ë°€ë„ ëª¨ë¸ ì‚¬ìš© ê¶Œìž¥ - ë†’ì€ ì •í™•ë„\")\n",
    "\n",
    "print(f\"   ðŸŽ¯ ì œìŠ¤ì²˜ë¥¼ í¬ê³  ëª…í™•í•˜ê²Œ ìˆ˜í–‰í•˜ì„¸ìš”\")\n",
    "print(f\"   ðŸ“– ìƒì„¸í•œ ì‚¬ìš©ë²•ì€ deployment_guide_improved.md ì°¸ì¡°\")\n",
    "\n",
    "print(f\"\\nâœ¨ ê°œì„ ëœ TinyML ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"   ë°ì´í„° ê²½ë¡œ: {DATA_ROOT}\")\n",
    "print(f\"   ëª¨ë¸ ê²½ë¡œ: {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
